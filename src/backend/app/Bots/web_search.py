import logging
from google import genai
from google.genai import types
from langchain_core.messages import AIMessage
from app.Bots.types import AgentState

logger = logging.getLogger(__name__)

# Inicializar cliente de Gemini (aseg√∫rate de tener GOOGLE_API_KEY en env)
gemini_client = genai.Client()


def web_search_node(state: AgentState) -> dict:
    """
    Agente de b√∫squeda web usando Google Grounding con Gemini.
    No requiere tools separadas, Gemini busca directamente en Google.
    """
    state.setdefault('trace', []).append('web_search')
    logger.info("[web_search] Ejecutando web search con Google Grounding. Mensaje: %s", 
                state['messages'][-1].content)
    
    try:
        # Obtener el √∫ltimo mensaje del usuario
        last_message = state['messages'][-1].content
        
        # Construir el contexto de conversaci√≥n para Gemini
        conversation_context = _build_conversation_context(state['messages'])
        
        # Configurar la herramienta de Google Search
        grounding_tool = types.Tool(
            google_search=types.GoogleSearch()
        )
        
        # Configuraci√≥n para generaci√≥n de contenido con grounding
        config = types.GenerateContentConfig(
            tools=[grounding_tool],
            temperature=0.2,  # Baja temperatura para respuestas m√°s precisas
            top_p=0.9,
            response_modalities=["TEXT"],
        )
        
        # Construir el prompt optimizado
        prompt = f"""Eres un experto asistente de f√∫tbol con acceso a b√∫squeda web en tiempo real.

Contexto de conversaci√≥n:
{conversation_context}

Pregunta actual del usuario: {last_message}

INSTRUCCIONES:
1. Busca informaci√≥n actualizada y precisa sobre la pregunta
2. Proporciona respuestas espec√≠ficas con datos concretos (fechas, resultados, equipos, etc.)
3. S√© conciso pero informativo
4. Si mencionas informaci√≥n de fuentes, hazlo de manera natural
5. Responde en espa√±ol de forma conversacional

Responde la pregunta del usuario bas√°ndote en la informaci√≥n m√°s reciente disponible."""

        # Realizar la b√∫squeda y generaci√≥n con Gemini
        logger.info("[web_search] Realizando b√∫squeda con Google Grounding...")
        response = gemini_client.models.generate_content(
            model="gemini-2.5-flash-lite", 
            contents=prompt,
            config=config,
        )
        
        # Extraer informaci√≥n de la respuesta
        response_text = response.text
        grounding_metadata = response.candidates[0].grounding_metadata if response.candidates else None
        
        # Construir respuesta enriquecida con metadata
        enhanced_response = _build_enhanced_response(response_text, grounding_metadata)
        
        logger.info("[web_search] B√∫squeda completada exitosamente")
        logger.debug("[web_search] Metadata de grounding: %s", grounding_metadata)
        
        # Crear mensaje AI con la respuesta
        ai_message = AIMessage(content=enhanced_response)
        
        return {
            "messages": state['messages'] + [ai_message],
            "needs_critic": True,
            "next_step": "critic",
            "trace": state.get('trace'),
            "origin": "web_search",
            "web_search_attempts": state.get('web_search_attempts', 0),
            "grounding_metadata": grounding_metadata  # Guardar metadata para an√°lisis
        }
    
    except Exception as e:
        logger.exception("[web_search] Error al realizar b√∫squeda con Google Grounding: %s", e)
        
        # Respuesta de fallback
        error_message = AIMessage(
            content=f"Lo siento, tuve un problema al buscar informaci√≥n actualizada sobre tu consulta. "
                   f"Error: {str(e)[:100]}"
        )
        
        return {
            "messages": state['messages'] + [error_message],
            "needs_critic": True,
            "next_step": "critic",
            "trace": state.get('trace'),
            "origin": "web_search",
            "web_search_attempts": state.get('web_search_attempts', 0) + 1
        }


def _build_conversation_context(messages: list, max_messages: int = 3) -> str:
    """
    Construye un resumen del contexto de conversaci√≥n reciente.
    
    Args:
        messages: Lista de mensajes de la conversaci√≥n
        max_messages: N√∫mero m√°ximo de mensajes a incluir
    
    Returns:
        String con el contexto de conversaci√≥n
    """
    # Obtener los √∫ltimos N mensajes (excluyendo el √∫ltimo que ya se procesa)
    recent_messages = messages[-(max_messages + 1):-1] if len(messages) > 1 else []
    
    if not recent_messages:
        return "Esta es la primera pregunta del usuario."
    
    context_parts = []
    for msg in recent_messages:
        role = "Usuario" if hasattr(msg, 'type') and msg.type == "human" else "Asistente"
        content = msg.content[:200] + "..." if len(msg.content) > 200 else msg.content
        context_parts.append(f"{role}: {content}")
    
    return "\n".join(context_parts)


def _build_enhanced_response(response_text: str, grounding_metadata) -> str:
    """
    Construye una respuesta enriquecida con informaci√≥n de grounding.
    
    Args:
        response_text: Texto de respuesta de Gemini
        grounding_metadata: Metadata de grounding de Google
    
    Returns:
        Respuesta enriquecida con fuentes (si est√°n disponibles)
    """
    enhanced = response_text
    
    # Si hay metadata de grounding, agregar referencias a las fuentes
    if grounding_metadata and hasattr(grounding_metadata, 'grounding_chunks'):
        chunks = grounding_metadata.grounding_chunks
        
        if chunks and len(chunks) > 0:
            # Extraer fuentes √∫nicas
            sources = []
            seen_domains = set()
            
            for chunk in chunks[:5]:  # M√°ximo 5 fuentes
                if hasattr(chunk, 'web') and chunk.web:
                    domain = chunk.web.title if hasattr(chunk.web, 'title') else chunk.web.uri
                    if domain and domain not in seen_domains:
                        sources.append(f"‚Ä¢ {domain}")
                        seen_domains.add(domain)
            
            # Agregar fuentes al final de la respuesta si existen
            if sources:
                enhanced += "\n\nüìö *Fuentes consultadas:*\n" + "\n".join(sources)
    
    # Agregar indicador de b√∫squeda web realizada
    if grounding_metadata and hasattr(grounding_metadata, 'web_search_queries'):
        queries = grounding_metadata.web_search_queries
        if queries:
            logger.debug("[web_search] Queries de b√∫squeda utilizadas: %s", queries)
    
    return enhanced


def _format_grounding_support(grounding_metadata) -> str:
    """
    Formatea informaci√≥n detallada de grounding support para debugging.
    
    Args:
        grounding_metadata: Metadata de grounding
    
    Returns:
        String formateado con informaci√≥n de soporte
    """
    if not grounding_metadata:
        return "Sin metadata de grounding"
    
    info = []
    
    if hasattr(grounding_metadata, 'web_search_queries'):
        info.append(f"Queries: {grounding_metadata.web_search_queries}")
    
    if hasattr(grounding_metadata, 'grounding_chunks'):
        info.append(f"Chunks: {len(grounding_metadata.grounding_chunks)}")
    
    if hasattr(grounding_metadata, 'grounding_supports'):
        info.append(f"Supports: {len(grounding_metadata.grounding_supports)}")
    
    return " | ".join(info)